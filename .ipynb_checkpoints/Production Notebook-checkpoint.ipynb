{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libaries and Production models\n",
    "---\n",
    "\n",
    "We'll need import the following libaries and procution models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from scipy.stats import kurtosis, skew\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "ss = joblib.load('ss.pkl')\n",
    "pca = joblib.load('pca.pkl')\n",
    "rfc = joblib.load('rfc.pkl')\n",
    "cnn = joblib.load('cnn.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receiving audio files from users\n",
    "---\n",
    "\n",
    "During deployment, we will receive audio files from users and try to make predictions on the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList = librosa.util.find_files('./audio', ext = ['wav', 'm4a'], limit = 1)\n",
    "digits = [librosa.load(f, sr = 44100) for f in fileList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = pd.DataFrame(digits)\n",
    "digits.drop(columns = 1, inplace = True)\n",
    "digits.rename(columns = {0: 'Speech_Raw'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Resample_1kHz(x):\n",
    "    return np.array(librosa.resample(x, orig_sr = 44100, target_sr = 1000))\n",
    "def Cut_1sec(x):\n",
    "    peak = librosa.util.peak_pick(x, 1000, 1000, 1000, 1000, 0, 1000)\n",
    "    cut = x[(peak[0] - 500):(peak[0] + 500)]\n",
    "    pad = librosa.util.pad_center(cut, 1000)\n",
    "    return pad\n",
    "\n",
    "digits['Speech_1kHz'] = digits['Speech_Raw'].apply(Resample_1kHz)\n",
    "digits['Speech_1sec'] = digits['Speech_1kHz'].apply(Cut_1sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Machine Learning Prediction\n",
    "---\n",
    "\n",
    "We will apply the same preprocessing steps, but only on 1 audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AbsMean(x):\n",
    "    out = np.abs(x)\n",
    "    return out.mean()\n",
    "def SD(x):\n",
    "    return x.std()\n",
    "def Skewness(x):\n",
    "    return skew(x)\n",
    "def Kurtosis(x):\n",
    "    return kurtosis(x, fisher = True)\n",
    "def RMS(x):\n",
    "    data = librosa.feature.rms(x, frame_length = 1000, hop_length = 1001)\n",
    "    return data[0][0]\n",
    "def Flat(x):\n",
    "    data = librosa.feature.spectral_flatness(x, hop_length = 1001)\n",
    "    return data[0][0]\n",
    "def ZCR(x):\n",
    "    data = librosa.feature.zero_crossing_rate(x, frame_length = 1000, hop_length = 1001)\n",
    "    return data[0][0]\n",
    "def Centroid(x):\n",
    "    data = librosa.feature.spectral_centroid(x, sr = 1000, hop_length = 1001)\n",
    "    return data[0][0]\n",
    "\n",
    "digits['AbsMean'] = digits['Speech_1sec'].apply(AbsMean)\n",
    "digits['SD'] = digits['Speech_1sec'].apply(SD)\n",
    "digits['Skewness'] = digits['Speech_1sec'].apply(Skewness)\n",
    "digits['Kurtosis'] = digits['Speech_1sec'].apply(Kurtosis)\n",
    "digits['RMS'] = digits['Speech_1sec'].apply(RMS)\n",
    "digits['Flat'] = digits['Speech_1sec'].apply(Flat)\n",
    "digits['ZCR'] = digits['Speech_1sec'].apply(ZCR)\n",
    "digits['Centroid'] = digits['Speech_1sec'].apply(Centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFCC1(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[0].mean()\n",
    "def MFCC2(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[1].mean()\n",
    "def MFCC3(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[2].mean()\n",
    "def MFCC4(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[3].mean()\n",
    "def MFCC5(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[4].mean()\n",
    "def MFCC6(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[5].mean()\n",
    "def MFCC7(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[6].mean()\n",
    "def MFCC8(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[7].mean()\n",
    "def MFCC9(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[8].mean()\n",
    "def MFCC10(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[9].mean()\n",
    "def MFCC11(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[10].mean()\n",
    "def MFCC12(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[11].mean()\n",
    "def MFCC13(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[12].mean()\n",
    "\n",
    "digits['MFCC1'] = digits['Speech_1sec'].apply(MFCC1)\n",
    "digits['MFCC2'] = digits['Speech_1sec'].apply(MFCC2)\n",
    "digits['MFCC3'] = digits['Speech_1sec'].apply(MFCC3)\n",
    "digits['MFCC4'] = digits['Speech_1sec'].apply(MFCC4)\n",
    "digits['MFCC5'] = digits['Speech_1sec'].apply(MFCC5)\n",
    "digits['MFCC6'] = digits['Speech_1sec'].apply(MFCC6)\n",
    "digits['MFCC7'] = digits['Speech_1sec'].apply(MFCC7)\n",
    "digits['MFCC8'] = digits['Speech_1sec'].apply(MFCC8)\n",
    "digits['MFCC9'] = digits['Speech_1sec'].apply(MFCC9)\n",
    "digits['MFCC10'] = digits['Speech_1sec'].apply(MFCC10)\n",
    "digits['MFCC11'] = digits['Speech_1sec'].apply(MFCC11)\n",
    "digits['MFCC12'] = digits['Speech_1sec'].apply(MFCC12)\n",
    "digits['MFCC13'] = digits['Speech_1sec'].apply(MFCC13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LPC1(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[1]\n",
    "def LPC2(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[2]\n",
    "def LPC3(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[3]\n",
    "def LPC4(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[4]\n",
    "def LPC5(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[5]\n",
    "def LPC6(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[6]\n",
    "def LPC7(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[7]\n",
    "def LPC8(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[8]\n",
    "def LPC9(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[9]\n",
    "def LPC10(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[10]\n",
    "def LPC11(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[11]\n",
    "def LPC12(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[12]\n",
    "\n",
    "digits['LPC1'] = digits['Speech_1sec'].apply(LPC1)\n",
    "digits['LPC2'] = digits['Speech_1sec'].apply(LPC2)\n",
    "digits['LPC3'] = digits['Speech_1sec'].apply(LPC3)\n",
    "digits['LPC4'] = digits['Speech_1sec'].apply(LPC4)\n",
    "digits['LPC5'] = digits['Speech_1sec'].apply(LPC5)\n",
    "digits['LPC6'] = digits['Speech_1sec'].apply(LPC6)\n",
    "digits['LPC7'] = digits['Speech_1sec'].apply(LPC7)\n",
    "digits['LPC8'] = digits['Speech_1sec'].apply(LPC8)\n",
    "digits['LPC9'] = digits['Speech_1sec'].apply(LPC9)\n",
    "digits['LPC10'] = digits['Speech_1sec'].apply(LPC10)\n",
    "digits['LPC11'] = digits['Speech_1sec'].apply(LPC11)\n",
    "digits['LPC12'] = digits['Speech_1sec'].apply(LPC12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['AbsMean', 'SD', 'Skewness', 'Kurtosis', 'RMS', 'Flat', 'ZCR', 'Centroid', 'LPC1', 'LPC2',\n",
    "            'LPC3', 'LPC4', 'LPC5', 'LPC6', 'LPC7', 'LPC8', 'LPC9', 'LPC10', 'LPC11', 'LPC12',\n",
    "            'MFCC1', 'MFCC2', 'MFCC3', 'MFCC4', 'MFCC5', 'MFCC6', 'MFCC7', 'MFCC8', 'MFCC9', 'MFCC10',\n",
    "            'MFCC11', 'MFCC12', 'MFCC13']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Prediction\n",
    "---\n",
    "\n",
    "We will use the pre-trained RFC model to make the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sc = ss.transform(digits[features])\n",
    "Z = pca.transform(X_sc)\n",
    "pred = rfc.predict(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Deep Learning Prediction\n",
    "---\n",
    "\n",
    "Similarly, we will apply the same deep learning preprocessing steps, but only on 1 audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =[]\n",
    "for i in range(0,digits.shape[0]):\n",
    "    X.append(digits.Speech_1sec[i].reshape(1000, 1))\n",
    "    \n",
    "X = np.array(X).reshape(-1, 1000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cnn.predict_classes(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Prediction\n",
    "---\n",
    "\n",
    "We will use the pre-trained CNN model to make the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
