{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libaries and Production models\n",
    "---\n",
    "\n",
    "We'll need import the following libaries and production models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy\n",
    "import speech_recognition as sr\n",
    "\n",
    "from scipy.stats import kurtosis, skew\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = joblib.load('ss.pkl')\n",
    "pca = joblib.load('pca.pkl')\n",
    "rfc = joblib.load('rfc.pkl')\n",
    "cnn = load_model('cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receiving audio files from users\n",
    "---\n",
    "\n",
    "During deployment, we will receive 1 audio file request at a time from the user and try to make predictions on the spoken digits. The current implementation assumes the following user requirements:\n",
    "- Recording of up to 15 seconds\n",
    "- Waypoint of 10 digits (0 to 9). English words (e.g. decimal or dot) not supported yet.\n",
    "- Any codec supported by `soundfile` or `audioread` is supposed to work. Tested wav format.\n",
    "- Stereo or Mono channel(s), RFC and CNN trained on mono channel.\n",
    "- Around 1 second duration per digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = [librosa.load('./audio/Mix001_9_210.wav', sr = 44100, mono = True, duration = 15)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Machine Learning Prediction\n",
    "---\n",
    "\n",
    "We will apply the same preprocessing steps, but only on 1 audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AbsMean(x):\n",
    "    out = np.abs(x)\n",
    "    return out.mean()\n",
    "def SD(x):\n",
    "    return x.std()\n",
    "def Skewness(x):\n",
    "    return skew(x)\n",
    "def Kurtosis(x):\n",
    "    return kurtosis(x, fisher = True)\n",
    "def RMS(x):\n",
    "    data = librosa.feature.rms(x, frame_length = 1000, hop_length = 1001)\n",
    "    return data[0][0]\n",
    "def Flat(x):\n",
    "    data = librosa.feature.spectral_flatness(x, hop_length = 1001)\n",
    "    return data[0][0]\n",
    "def ZCR(x):\n",
    "    data = librosa.feature.zero_crossing_rate(x, frame_length = 1000, hop_length = 1001)\n",
    "    return data[0][0]\n",
    "def Centroid(x):\n",
    "    data = librosa.feature.spectral_centroid(x, sr = 1000, hop_length = 1001)\n",
    "    return data[0][0]\n",
    "def MFCC1(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[0].mean()\n",
    "def MFCC2(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[1].mean()\n",
    "def MFCC3(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[2].mean()\n",
    "def MFCC4(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[3].mean()\n",
    "def MFCC5(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[4].mean()\n",
    "def MFCC6(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[5].mean()\n",
    "def MFCC7(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[6].mean()\n",
    "def MFCC8(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[7].mean()\n",
    "def MFCC9(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[8].mean()\n",
    "def MFCC10(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[9].mean()\n",
    "def MFCC11(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[10].mean()\n",
    "def MFCC12(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[11].mean()\n",
    "def MFCC13(x):\n",
    "    data = librosa.feature.mfcc(x, sr = 1000, n_mfcc = 13)\n",
    "    return data[12].mean()\n",
    "def LPC1(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[1]\n",
    "def LPC2(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[2]\n",
    "def LPC3(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[3]\n",
    "def LPC4(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[4]\n",
    "def LPC5(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[5]\n",
    "def LPC6(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[6]\n",
    "def LPC7(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[7]\n",
    "def LPC8(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[8]\n",
    "def LPC9(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[9]\n",
    "def LPC10(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[10]\n",
    "def LPC11(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[11]\n",
    "def LPC12(x):\n",
    "    LPC = librosa.core.lpc(x, 12)\n",
    "    return LPC[12]\n",
    "def RFC_Single():\n",
    "    pred = None\n",
    "    digits = [librosa.load('./tmp/single/single.wav', sr = 44100)]\n",
    "    digits = pd.DataFrame(digits)\n",
    "    digits.drop(columns = 1, inplace = True)\n",
    "    digits.rename(columns = {0: 'Speech_Raw'}, inplace = True)\n",
    "    digits['Speech_1kHz'] = digits['Speech_Raw'].apply(Resample_1kHz)\n",
    "    digits['Speech_1sec'] = digits['Speech_1kHz'].apply(Cut_1sec)    \n",
    "    digits['AbsMean'] = digits['Speech_1sec'].apply(AbsMean)\n",
    "    digits['SD'] = digits['Speech_1sec'].apply(SD)\n",
    "    digits['Skewness'] = digits['Speech_1sec'].apply(Skewness)\n",
    "    digits['Kurtosis'] = digits['Speech_1sec'].apply(Kurtosis)\n",
    "    digits['RMS'] = digits['Speech_1sec'].apply(RMS)\n",
    "    digits['Flat'] = digits['Speech_1sec'].apply(Flat)\n",
    "    digits['ZCR'] = digits['Speech_1sec'].apply(ZCR)\n",
    "    digits['Centroid'] = digits['Speech_1sec'].apply(Centroid)\n",
    "    digits['MFCC1'] = digits['Speech_1sec'].apply(MFCC1)\n",
    "    digits['MFCC2'] = digits['Speech_1sec'].apply(MFCC2)\n",
    "    digits['MFCC3'] = digits['Speech_1sec'].apply(MFCC3)\n",
    "    digits['MFCC4'] = digits['Speech_1sec'].apply(MFCC4)\n",
    "    digits['MFCC5'] = digits['Speech_1sec'].apply(MFCC5)\n",
    "    digits['MFCC6'] = digits['Speech_1sec'].apply(MFCC6)\n",
    "    digits['MFCC7'] = digits['Speech_1sec'].apply(MFCC7)\n",
    "    digits['MFCC8'] = digits['Speech_1sec'].apply(MFCC8)\n",
    "    digits['MFCC9'] = digits['Speech_1sec'].apply(MFCC9)\n",
    "    digits['MFCC10'] = digits['Speech_1sec'].apply(MFCC10)\n",
    "    digits['MFCC11'] = digits['Speech_1sec'].apply(MFCC11)\n",
    "    digits['MFCC12'] = digits['Speech_1sec'].apply(MFCC12)\n",
    "    digits['MFCC13'] = digits['Speech_1sec'].apply(MFCC13)\n",
    "    digits['LPC1'] = digits['Speech_1sec'].apply(LPC1)\n",
    "    digits['LPC2'] = digits['Speech_1sec'].apply(LPC2)\n",
    "    digits['LPC3'] = digits['Speech_1sec'].apply(LPC3)\n",
    "    digits['LPC4'] = digits['Speech_1sec'].apply(LPC4)\n",
    "    digits['LPC5'] = digits['Speech_1sec'].apply(LPC5)\n",
    "    digits['LPC6'] = digits['Speech_1sec'].apply(LPC6)\n",
    "    digits['LPC7'] = digits['Speech_1sec'].apply(LPC7)\n",
    "    digits['LPC8'] = digits['Speech_1sec'].apply(LPC8)\n",
    "    digits['LPC9'] = digits['Speech_1sec'].apply(LPC9)\n",
    "    digits['LPC10'] = digits['Speech_1sec'].apply(LPC10)\n",
    "    digits['LPC11'] = digits['Speech_1sec'].apply(LPC11)\n",
    "    digits['LPC12'] = digits['Speech_1sec'].apply(LPC12)\n",
    "    features = ['AbsMean', 'SD', 'Skewness', 'Kurtosis', 'RMS', 'Flat', 'ZCR', 'Centroid', 'LPC1', 'LPC2', 'LPC3', 'LPC4', 'LPC5', 'LPC6', 'LPC7', 'LPC8', 'LPC9', 'LPC10', 'LPC11', 'LPC12', 'MFCC1', 'MFCC2', 'MFCC3', 'MFCC4', 'MFCC5', 'MFCC6', 'MFCC7', 'MFCC8', 'MFCC9', 'MFCC10', 'MFCC11', 'MFCC12', 'MFCC13']\n",
    "    X_sc = ss.transform(digits[features])\n",
    "    Z = pca.transform(X_sc)\n",
    "    pred = rfc.predict(Z)\n",
    "    return str(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['AbsMean', 'SD', 'Skewness', 'Kurtosis', 'RMS', 'Flat', 'ZCR', 'Centroid', 'LPC1', 'LPC2',\n",
    "            'LPC3', 'LPC4', 'LPC5', 'LPC6', 'LPC7', 'LPC8', 'LPC9', 'LPC10', 'LPC11', 'LPC12',\n",
    "            'MFCC1', 'MFCC2', 'MFCC3', 'MFCC4', 'MFCC5', 'MFCC6', 'MFCC7', 'MFCC8', 'MFCC9', 'MFCC10',\n",
    "            'MFCC11', 'MFCC12', 'MFCC13']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Deep Learning Prediction\n",
    "---\n",
    "\n",
    "Similarly, we will apply the same deep learning preprocessing steps, but only on 1 audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_Single():\n",
    "    pred = None\n",
    "    digits = [librosa.load('./tmp/single/single.wav', sr = 44100)]\n",
    "    digits = pd.DataFrame(digits)\n",
    "    digits.drop(columns = 1, inplace = True)\n",
    "    digits.rename(columns = {0: 'Speech_Raw'}, inplace = True)\n",
    "    digits['Speech_1kHz'] = digits['Speech_Raw'].apply(Resample_1kHz)\n",
    "    digits['Speech_1sec'] = digits['Speech_1kHz'].apply(Cut_1sec)\n",
    "    X =[]\n",
    "    for i in range(0,digits.shape[0]):\n",
    "        X.append(digits.Speech_1sec[i].reshape(1000, 1))\n",
    "    X = np.array(X).reshape(-1, 1000, 1)\n",
    "    pred = cnn.predict_classes(X)\n",
    "    return str(pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning and Deep Learning Predictions\n",
    "---\n",
    "\n",
    "We will use the pre-trained RFC and CNN models to make the predictions.\n",
    "\n",
    "By default, we will do onset peak detection to find the first digit, center and pad the frame if required. In the subsequent digits, we will also try to do same if the interval is more than 1sec. However, if the interval is less than 1 sec, we will automatically cut the clip into 1 sec segments and proceed with the predicition.\n",
    "\n",
    "The current implementation also destroys all data (both pre-processed and post-processed) after making the prediction. (i.e. the App on AWS server destroy the data whenever it no longer needs it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Resample_1kHz(x):\n",
    "    return np.array(librosa.resample(x, orig_sr = 44100, target_sr = 1000))\n",
    "def Cut_1sec(x):\n",
    "    peak = librosa.util.peak_pick(x, 1000, 1000, 1000, 1000, 0, 1000)\n",
    "    cut = x[(peak[0] - 500):(peak[0] + 500)]\n",
    "    pad = librosa.util.pad_center(cut, 1000)\n",
    "    return pad\n",
    "def remaining_cut(x):\n",
    "    peak = librosa.util.peak_pick(x, 1000, 1000, 1000, 1000, 0.1, 1000)\n",
    "    print('len: ', len(peak))\n",
    "    if len(peak) == 0:\n",
    "        return 'Nothing to cut'\n",
    "    if peak <= 1000:\n",
    "        cut = x[0:1000]\n",
    "        pad = librosa.util.pad_center(cut, 1000)\n",
    "    if peak > 1000:\n",
    "        cut = x[(peak[0] - 500):(peak[0] + 500)]\n",
    "        pad = librosa.util.pad_center(cut, 1000)\n",
    "    return pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = pd.DataFrame(digits)\n",
    "digits.drop(columns = 1, inplace = True)\n",
    "digits.rename(columns = {0: 'Speech_Raw'}, inplace = True)\n",
    "digits['Speech_1kHz'] = digits['Speech_Raw'].apply(Resample_1kHz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 10\n",
    "peak = librosa.util.peak_pick(digits['Speech_1kHz'][0], 1000, 1000, 1000, 1000, 0.1, 1000)\n",
    "cut = digits['Speech_1kHz'][0][(peak[0] - 500):(peak[0] + 500)]\n",
    "pad = librosa.util.pad_center(cut, 1000)\n",
    "librosa.output.write_wav('./tmp/single/single.wav', pad, sr = 1000)\n",
    "RFC_Predict = RFC_Single()\n",
    "RFC_Digits = RFC_Predict\n",
    "CNN_Predict = CNN_Single()\n",
    "CNN_Digits = CNN_Predict\n",
    "os.remove('./tmp/single/single.wav')\n",
    "remaining = digits['Speech_1kHz'][0][(peak[0] + 500):len(digits['Speech_1kHz'][0])]\n",
    "counter -=1\n",
    "if len(remaining) == 0:\n",
    "    counter = 0\n",
    "while counter > 0:\n",
    "    cut = pd.DataFrame(remaining).apply(remaining_cut)\n",
    "    if str(cut[0]) == 'Nothing to cut':\n",
    "        break\n",
    "    pad = librosa.util.pad_center(cut, 1000)\n",
    "    librosa.output.write_wav('./tmp/single/single.wav', pad[0], sr = 1000)\n",
    "    RFC_Predict = RFC_Single()\n",
    "    CNN_Predict = CNN_Single()\n",
    "    RFC_Digits = RFC_Digits + RFC_Predict\n",
    "    CNN_Digits = CNN_Digits + CNN_Predict\n",
    "    os.remove('./tmp/single/single.wav')\n",
    "    remaining = remaining[1000:len(remaining)]\n",
    "    counter -=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Prediction:  9\n",
      "CNN Prediction:  9\n"
     ]
    }
   ],
   "source": [
    "print('RFC Prediction: ', RFC_Digits)\n",
    "print('CNN Prediction: ', CNN_Digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Speech Recognition Prediction\n",
    "---\n",
    "\n",
    "Last but not least, we include Google Speech Recognition's prediction as reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Google_API(x):\n",
    "    output = None\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(x) as source:\n",
    "        google = r.record(source)\n",
    "    try:\n",
    "        output = r.recognize_google(google)\n",
    "    except sr.RequestError:\n",
    "        output = 'API unavailable or unresponsive'\n",
    "    except sr.UnknownValueError:\n",
    "        output = 'Sorry, speech was unintelligible'\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Google_Predict = Google_API('./audio/Mix001_0_001.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Prediction:  0\n"
     ]
    }
   ],
   "source": [
    "print('Google Prediction: ', Google_Predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
